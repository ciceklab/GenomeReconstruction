{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import timeit\n",
    "import itertools\n",
    "import warnings\n",
    "import pickle\n",
    "import feather\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join, isfile\n",
    "from collections import Counter\n",
    "from fcmeans import FCM\n",
    "import scipy.stats as stats\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, classification_report, mutual_info_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True, formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainPath = \"../../data\"\n",
    "beacons = join(mainPath, \"beacon\")\n",
    "testSets = join(beacons, \"testsets\")\n",
    "models = join(mainPath, \"models\")\n",
    "ceuPath = join(beacons, \"CEU\")\n",
    "opensnpPath = join(beacons, \"OpenSNP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: Load Beacon, MAF, Reference and other cached variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'EyeColor','HairType','HairColor','TanAbility','Asthma','LactoseIntolerance',#'BloodType',\n",
    "             'EarWax','Freckling','TongueRoller','RingFinger','Intolerance','WidowPeak','ADHD','Acrophobia',\n",
    "             'FingerHair','Myopia','IrritableBowel','IndexLongerBig','Photoptarmis','Migraine','RhProtein']\n",
    "with open(join(opensnpPath, \"OpenSNP_Phenotype.pickle\"), 'rb') as handle:\n",
    "    pheno = pickle.load(handle)\n",
    "pheno = pheno[features]\n",
    "pheno[pheno==\"Auburn\"] = \"Blonde\"\n",
    "pheno[pheno==\"Black\"] = \"Brown\"\n",
    "\n",
    "with open(join(opensnpPath, \"MAF.pickle\"), 'rb') as handle:\n",
    "    maf = pickle.load(handle)\n",
    "\n",
    "with open(join(opensnpPath, \"Reference.pickle\"), 'rb') as handle:\n",
    "    reference = pickle.load(handle)\n",
    "reference = reference.values\n",
    "\n",
    "with open(join(opensnpPath, \"Beacon.pickle\"), 'rb') as handle:\n",
    "    beacon = pickle.load(handle)\n",
    "\n",
    "with open(join(opensnpPath, \"BinaryBeacon.pickle\"), 'rb') as handle:\n",
    "    binary = pickle.load(handle)\n",
    "    \n",
    "with open(join(opensnpPath, \"TernaryBeacon.pickle\"), 'rb') as handle:\n",
    "    ternary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1, ..., -1,  0, -1],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  0, -1, ..., -1,  1, -1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  1,  1,  0],\n",
       "       [-1, -1, -1, ..., -1, -1, -1],\n",
       "       [-1, -1, -1, ..., -1, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ternary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6855</th>\n",
       "      <th>740</th>\n",
       "      <th>1775</th>\n",
       "      <th>2006</th>\n",
       "      <th>7958</th>\n",
       "      <th>6220</th>\n",
       "      <th>2983</th>\n",
       "      <th>2296</th>\n",
       "      <th>2570</th>\n",
       "      <th>5555</th>\n",
       "      <th>...</th>\n",
       "      <th>6786</th>\n",
       "      <th>6906</th>\n",
       "      <th>4741</th>\n",
       "      <th>4582</th>\n",
       "      <th>7634</th>\n",
       "      <th>7505</th>\n",
       "      <th>1706</th>\n",
       "      <th>6206</th>\n",
       "      <th>5201</th>\n",
       "      <th>6084</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rs10</th>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>AC</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs1000000</th>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>NN</td>\n",
       "      <td>GG</td>\n",
       "      <td>AA</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>...</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>AG</td>\n",
       "      <td>GG</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs10000010</th>\n",
       "      <td>CT</td>\n",
       "      <td>TT</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CT</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>CT</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs10000012</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs1000002</th>\n",
       "      <td>TT</td>\n",
       "      <td>CT</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>CT</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CT</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>TT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs9999978</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs9999979</th>\n",
       "      <td>CT</td>\n",
       "      <td>CC</td>\n",
       "      <td>TT</td>\n",
       "      <td>TT</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>CT</td>\n",
       "      <td>TT</td>\n",
       "      <td>NN</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>TT</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CT</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CT</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs9999992</th>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>NN</td>\n",
       "      <td>AG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>AG</td>\n",
       "      <td>GG</td>\n",
       "      <td>...</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>GG</td>\n",
       "      <td>AG</td>\n",
       "      <td>AG</td>\n",
       "      <td>GG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs9999995</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs9999998</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2338573 rows × 2979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           6855 740 1775 2006 7958 6220 2983 2296 2570 5555  ... 6786 6906  \\\n",
       "rs_id                                                        ...             \n",
       "rs10         CC  CC   NN   NN   NN   NN   CC   NN   NN   NN  ...   AC   NN   \n",
       "rs1000000    GG  GG   GG   GG   NN   GG   AA   GG   GG   GG  ...   GG   GG   \n",
       "rs10000010   CT  TT   NN   NN   NN   NN   CT   NN   NN   NN  ...   CT   NN   \n",
       "rs10000012   NN  NN   NN   NN   NN   NN   NN   NN   NN   NN  ...   NN   NN   \n",
       "rs1000002    TT  CT   NN   NN   CC   NN   CT   NN   NN   NN  ...   CC   NN   \n",
       "...         ...  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "rs9999978    NN  NN   NN   NN   NN   NN   NN   NN   NN   NN  ...   NN   NN   \n",
       "rs9999979    CT  CC   TT   TT   NN   CC   CT   TT   NN   CT  ...   TT   CC   \n",
       "rs9999992    GG  GG   GG   GG   NN   AG   GG   GG   AG   GG  ...   GG   GG   \n",
       "rs9999995    NN  NN   NN   NN   NN   NN   NN   NN   NN   NN  ...   NN   NN   \n",
       "rs9999998    NN  NN   NN   NN   NN   NN   NN   NN   NN   NN  ...   NN   NN   \n",
       "\n",
       "           4741 4582 7634 7505 1706 6206 5201 6084  \n",
       "rs_id                                               \n",
       "rs10         CC   NN   NN   NN   NN   NN   CC   NN  \n",
       "rs1000000    AG   GG   NN   NN   GG   GG   GG   GG  \n",
       "rs10000010   CC   NN   NN   NN   NN   NN   CT   NN  \n",
       "rs10000012   NN   NN   NN   NN   NN   NN   NN   NN  \n",
       "rs1000002    CC   NN   NN   CT   NN   NN   TT   NN  \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "rs9999978    NN   NN   NN   NN   NN   NN   NN   NN  \n",
       "rs9999979    CC   CT   NN   NN   CC   CC   CT   CC  \n",
       "rs9999992    GG   GG   NN   NN   GG   AG   AG   GG  \n",
       "rs9999995    NN   NN   NN   NN   NN   NN   NN   NN  \n",
       "rs9999998    NN   NN   NN   NN   NN   NN   NN   NN  \n",
       "\n",
       "[2338573 rows x 2979 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beacon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constrainted Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno5People = pheno.iloc[np.where(np.sum(pheno != \"-\", axis = 1) >=10)[0]].index\n",
    "pheno5People = pheno5People.map(str)\n",
    "pheno5People = np.where(beacon.columns.isin(pheno5People))[0]\n",
    "\n",
    "pheno1People = pheno.iloc[np.where(np.sum(pheno != \"-\", axis = 1) >= 1)[0]].index\n",
    "pheno1People = pheno1People.map(str)\n",
    "pheno1People = np.where(beacon.columns.isin(pheno1People))[0]\n",
    "\n",
    "phenoAllPeople = np.arange(beacon.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1.2: PCA and Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 668, 0: 536, 2: 116})\n",
      "[[517.16 18.28 0.50 -2.28]\n",
      " [-343.34 -188.36 2.14 1.20]\n",
      " [-412.45 1000.26 -14.64 3.62]]\n",
      "CPU times: user 4min 19s, sys: 14.6 s, total: 4min 34s\n",
      "Wall time: 56.6 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=4)\n",
    "tr1 = pca.fit_transform(ternary[:, pheno1People].T)\n",
    "plt.scatter(tr1[:, 0], tr1[:, 1], alpha=0.4)\n",
    "\n",
    "kmeans = KMeans(3)\n",
    "y_kmeans = kmeans.fit_predict(tr1)\n",
    "plt.scatter(tr1[:, 0], tr1[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "print(Counter(y_kmeans))\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536,) (668,) (116,)\n",
      "(94,) (60,) (5,)\n"
     ]
    }
   ],
   "source": [
    "# Get indices of homogeneous groups\n",
    "g1 = pheno1People[np.where(y_kmeans == 0)[0]]\n",
    "g2 = pheno1People[np.where(y_kmeans == 1)[0]]\n",
    "g3 = pheno1People[np.where(y_kmeans == 2)[0]]\n",
    "print(g1.shape, g2.shape, g3.shape)\n",
    "\n",
    "g1a = np.intersect1d(g1, pheno5People)\n",
    "g2a = np.intersect1d(g2, pheno5People)\n",
    "g3a = np.intersect1d(g3, pheno5People)\n",
    "print(g1a.shape, g2a.shape, g3a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1.2: Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beacon operations\n",
    "def queryBeacon(beacon_people):\n",
    "    return binary[:, beacon_people].any(axis=1)\n",
    "\n",
    "def getMutationAt(index):\n",
    "    temp = maf.iloc[index]\n",
    "    if temp[\"minor_freq\"] == temp[\"maf\"]:\n",
    "        return temp[\"minor\"] + temp[\"minor\"] \n",
    "    else:\n",
    "        return temp[\"major\"] + temp[\"major\"] \n",
    "\n",
    "def div(n, d):\n",
    "    return n / d if d else 0\n",
    "\n",
    "def rpaCalculate(tp,fp,tn,fn):\n",
    "    recall = div(tp,(tp+fn)) \n",
    "    precision = div(tp,(tp+fp))\n",
    "    accuracy = div((tp+tn),(tp+fp+tn+fn))\n",
    "    return recall, precision, accuracy\n",
    "\n",
    "def getTrainingData(phenotype, pos, test_people):\n",
    "    # Find indices of people who has the specified feature\n",
    "    feature_label = pheno[pheno[phenotype] != \"-\"][phenotype]\n",
    "    existing = beacon.columns.isin(feature_label.index.values)\n",
    "    existing[test_people] = False \n",
    "    \n",
    "    # Get training data\n",
    "    X = binary[pos][:, existing].T\n",
    "    Y = feature_label[beacon.columns[existing]].values\n",
    "    return X, Y\n",
    "\n",
    "# Performance method\n",
    "def performance(person, reconstruction, eval_pos, reference):\n",
    "    ind = np.logical_and(person[eval_pos] != np.squeeze(reference)[eval_pos], person[eval_pos] != \"NN\")\n",
    "    tp = np.sum(reconstruction[eval_pos][ind] != np.squeeze(reference)[eval_pos][ind])\n",
    "    fn = np.sum(ind) - tp\n",
    "    fp = np.sum(reconstruction[eval_pos][~ind] != np.squeeze(reference)[eval_pos][~ind])\n",
    "    tn = np.sum(~ind) - fp\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def performance_f(test_people, reconstructed, add_count, cluster_count, eval_pos):\n",
    "    total_values = np.zeros((4))\n",
    "    best_matches = []\n",
    "    # For all people in victim set\n",
    "    for i in range(add_count):\n",
    "        all_combinations = np.zeros((4, cluster_count))\n",
    "        rpa = np.zeros((3, cluster_count))\n",
    "        # For each cluster obtained\n",
    "        for j in range(cluster_count):\n",
    "            all_combinations[:, j] = performance(test_people[i], reconstructed[j], eval_pos, reference)\n",
    "            rpa[:, j] = rpaCalculate(*all_combinations[:, j])\n",
    "        ind = np.argmax(rpa[0,:]*rpa[1,:])       #Best-match index\n",
    "        best_matches.append(ind)\n",
    "        total_values += all_combinations[:, ind] #Add total tp-fp-tn-fn\n",
    "    recall, precision, accuracy = rpaCalculate(*total_values)\n",
    "    print(\"Recall_Micro_Avg    =\", round(recall, 2),\"\\nPrecision_Micro_Avg =\", round(precision, 2))\n",
    "    return (precision,recall,accuracy), total_values, best_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2: Choose random people and send query to Beacon to obtain No-Yes answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoYes(add_count, beacon_size):\n",
    "\n",
    "    # Take people for added group\n",
    "    random.shuffle(g1a)\n",
    "    random.shuffle(g2a)\n",
    "    random.shuffle(g3a)\n",
    "    if add_count >= 5:\n",
    "        added_people = np.concatenate([g1a[:(2*add_count//5)], g2a[:(2*add_count//5)], g3a[:(add_count//5)]])\n",
    "    elif add_count == 3:\n",
    "        added_people = np.concatenate([g1a[:(add_count//3)], g2a[:(add_count//3)], g3a[:(add_count//3)]])\n",
    "    elif add_count == 2:\n",
    "        added_people = np.concatenate([g1a[:(add_count//2)], g2a[:(add_count//2)]])\n",
    "        \n",
    "    # Take people for beacon\n",
    "    g1_ = np.setdiff1d(g1, g1a)\n",
    "    random.shuffle(g1_)\n",
    "    g2_ = np.setdiff1d(g2, g2a)\n",
    "    random.shuffle(g2_)\n",
    "    g3_ = np.setdiff1d(g3, g3a)\n",
    "    random.shuffle(g3_)\n",
    "    if add_count >= 5:\n",
    "        curBeacon = np.concatenate([g1_[:(2*beacon_size//5)], g2_[:(2*beacon_size//5)], g3_[:(beacon_size//5)]])\n",
    "    elif add_count == 3:\n",
    "        curBeacon = np.concatenate([g1_[:(beacon_size//3)], g2_[:(beacon_size//3)], g3_[:(beacon_size//3)]])\n",
    "    elif add_count == 2:\n",
    "        curBeacon = np.concatenate([g1_[:(beacon_size//2)], g2_[:(beacon_size//2)]])\n",
    "        \n",
    "    \n",
    "    # Query Beacon initially\n",
    "    before = queryBeacon(curBeacon)\n",
    "    # Add people\n",
    "    updatedBeacon = np.concatenate([added_people,curBeacon])\n",
    "    # Query Beacon again\n",
    "    after = queryBeacon(updatedBeacon)\n",
    "    # Find No-Yes SNPs' indices\n",
    "    no_yes_indices = np.where(np.logical_and(before==False, after==True))[0]\n",
    "    yes_yes_indices = np.where(np.logical_and(before==True, after==True))[0]\n",
    "    print(\"Number of No-Yes SNP's : \", len(no_yes_indices))\n",
    "    \n",
    "    return yes_yes_indices, no_yes_indices, added_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoYes2(add_count, beacon_size):\n",
    "\n",
    "    # Take people for added group\n",
    "    added_people = pheno5People.copy()\n",
    "    random.shuffle(added_people)\n",
    "    added_people = added_people[:add_count]\n",
    "    \n",
    "    # Take people for beacon\n",
    "    beacon_people = np.setdiff1d(phenoAllPeople, added_people)\n",
    "    random.shuffle(beacon_people)\n",
    "    beacon_people = beacon_people[:beacon_size]\n",
    "\n",
    "    # Query Beacon initially\n",
    "    before = queryBeacon(beacon_people)\n",
    "    # Add people\n",
    "    updated_beacon = np.concatenate([added_people,beacon_people])\n",
    "    # Query Beacon again\n",
    "    after = queryBeacon(updated_beacon)\n",
    "    # Find No-Yes SNPs' indices\n",
    "    no_yes_indices = np.where(np.logical_and(before==False, after==True))[0]\n",
    "    yes_yes_indices = np.where(np.logical_and(before==True, after==True))[0]\n",
    "    print(\"Number of No-Yes SNP's : \", len(no_yes_indices))\n",
    "    \n",
    "    return yes_yes_indices, no_yes_indices, added_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3: Correlation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtSNPNetwork(no_yes_indices, model_ind, reference):\n",
    "    model = ternary[no_yes_ind][:, model_ind].astype(float)\n",
    "    model[model==-1] = np.nan\n",
    "    x = pairwise_distances(model, metric = \"sokalmichener\", n_jobs=-1)\n",
    "    x = 1-np.nan_to_num(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_method(no_yes_indices, add_count, cluster_count=None):\n",
    "    c = maf.iloc[no_yes_indices]\n",
    "\n",
    "    # Calculate probabilities of SNP possibilities\n",
    "    greater = c.loc[c['major_freq'] >= c['minor_freq']]\n",
    "    smaller = c.loc[c['major_freq'] < c['minor_freq']]\n",
    "\n",
    "    greater[\"maj-maj\"] = greater['major'] + \"\" + greater['major']\n",
    "    greater[\"mean\"] = pd.concat([greater['major'] + \"\" + greater['minor'], greater['minor'] + \"\" + greater['major']], axis=1).min(axis=1)\n",
    "    greater[\"min-min\"] = greater['minor'] + \"\" + greater['minor']\n",
    "    greater[\"p1\"] = greater['major_freq']**2\n",
    "    greater[\"p2\"] = 2*greater['major_freq']*greater['minor_freq']\n",
    "    greater[\"p3\"] = greater['minor_freq']**2\n",
    "\n",
    "    smaller[\"maj-maj\"] = smaller['minor'] + \"\" + smaller['minor']\n",
    "    smaller[\"mean\"] = pd.concat([smaller['major'] + \"\" + smaller['minor'], smaller['minor'] + \"\" + smaller['major']], axis=1).min(axis=1)\n",
    "    smaller[\"min-min\"] = smaller['major'] + \"\" + smaller['major']\n",
    "    smaller[\"p1\"] = smaller['minor_freq']**2\n",
    "    smaller[\"p2\"] = 2*smaller['major_freq']*smaller['minor_freq']\n",
    "    smaller[\"p3\"] = smaller['major_freq']**2\n",
    "\n",
    "    tt = pd.concat([greater,smaller], axis=0)\n",
    "    tt.sort_index(inplace=True)\n",
    "\n",
    "    genome_possibilities = tt[[\"maj-maj\", \"mean\", \"min-min\"]].values\n",
    "    probabilities = tt[[\"p1\",\"p2\",\"p3\"]].values\n",
    "\n",
    "    mutations = tt[[\"mean\", \"min-min\"]].values\n",
    "    mutation_probs = tt[[\"p2\",\"p3\"]].values\n",
    "\n",
    "    # Randomly reconstruct the people's genome\n",
    "    bins = []\n",
    "    cumulative = probabilities.cumsum(axis=1)\n",
    "    for i in range(add_count):\n",
    "        uniform = np.random.rand(len(cumulative), 1)\n",
    "        choices = (uniform < cumulative).argmax(axis=1)\n",
    "        reconstructed = np.choose(choices, genome_possibilities.T)\n",
    "        bins.append(reconstructed)\n",
    "    bins = np.array(bins)\n",
    "    \n",
    "    # Be sure that at least one person has the mutation\n",
    "    equality = np.sum((bins == reference[no_yes_indices].T), axis=0)\n",
    "    changed_indices = np.where(equality==add_count)[0]\n",
    "\n",
    "    index_choices = np.random.randint(add_count, size=len(equality))[changed_indices]\n",
    "\n",
    "    non_zeros = mutation_probs[np.sum(mutation_probs, axis=1) != 0]\n",
    "    probs = (non_zeros.T / np.sum(non_zeros, axis=1).T).T\n",
    "\n",
    "    zeros = np.zeros((mutation_probs.shape[0], 2))\n",
    "    zeros[np.sum(mutation_probs, axis=1) != 0] = probs\n",
    "    probs = zeros[changed_indices]\n",
    "\n",
    "    cum = probs.cumsum(axis=1)\n",
    "    uni = np.random.rand(len(cum), 1)\n",
    "    choi = (uni < cum).argmax(axis=1)\n",
    "    res = np.choose(choi, mutations[changed_indices].T)\n",
    "\n",
    "    bins.T[changed_indices, index_choices] = res\n",
    "    # Reconstruct\n",
    "    reconstructed = np.array([reference.T[0] for i in range(add_count)])\n",
    "    reconstructed.T[no_yes_indices] = bins.T\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectralClustering(no_yes_indices, add_count, x, reference, cluster_count=None):\n",
    "    if not cluster_count:\n",
    "        cluster_count = add_count\n",
    "    sc = SpectralClustering(cluster_count, affinity='precomputed', n_init=100, n_jobs=-1)\n",
    "    sc.fit(np.array(x))\n",
    "    bins = []\n",
    "    for i in range(cluster_count):\n",
    "        temp = []\n",
    "        for element in np.where(sc.labels_==i)[0]:\n",
    "            temp.append(no_yes_indices[element])\n",
    "        #print(\"Bin \" + str(i) + \" has \" + str(len(temp)) + \" SNP's\")\n",
    "        bins.append(temp)\n",
    "    reconstructed = np.array([reference.T[0] for i in range(cluster_count)])\n",
    "    for i in range(cluster_count):\n",
    "        for j in bins[i]:\n",
    "            reconstructed[i][j] = getMutationAt(j)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzyClustering(no_yes_indices, add_count, x, reference, cluster_count=None):\n",
    "    if not cluster_count:\n",
    "        cluster_count = add_count\n",
    "    fcm = FCM(n_clusters=cluster_count)\n",
    "    fcm.fit(correlations)\n",
    "    soft_clusters = fcm.u\n",
    "    bins = [[] for i in range(cluster_count)]\n",
    "    for i in range(len(soft_clusters)):\n",
    "        maxPos = np.argmax(soft_clusters[i])\n",
    "        if soft_clusters[i][maxPos] <= 0.5:\n",
    "            for j in np.where(soft_clusters[i] > (soft_clusters[i][maxPos] * 2 / 3))[0]:\n",
    "                bins[j].append(no_yes_indices[i])\n",
    "        else:\n",
    "            bins[maxPos].append(no_yes_indices[i])\n",
    "    reconstructed = np.array([reference.T[0] for i in range(cluster_count)])\n",
    "    for i in range(cluster_count):\n",
    "        for j in bins[i]:\n",
    "            reconstructed[i][j] = getMutationAt(j)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genome Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of No-Yes SNP's :  6274\n"
     ]
    }
   ],
   "source": [
    "add_count = 2\n",
    "cluster_count = 2\n",
    "beacon_size = 50\n",
    "yes_yes_ind, no_yes_ind, added_people     = getNoYes(add_count, beacon_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall_Micro_Avg    = 0.94 \n",
      "Precision_Micro_Avg = 0.95\n",
      "CPU times: user 57.5 s, sys: 1.16 s, total: 58.7 s\n",
      "Wall time: 6.19 s\n"
     ]
    }
   ],
   "source": [
    "model_ind = np.setdiff1d(pheno1People, added_people)\n",
    "correlations                              = builtSNPNetwork(no_yes_ind, model_ind, reference)\n",
    "reconstructed_spectral                    = spectralClustering(no_yes_ind, add_count, correlations, reference)\n",
    "(precision,recall,accuracy), _, matches   = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,add_count,cluster_count,no_yes_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Tests and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(2,20),(3,30),(4,40),(5,50),(10,100),(20,100)]\n",
    "res = []\n",
    "for e in experiments:\n",
    "    add_count = e[0]\n",
    "    beacon_size = e[1]\n",
    "\n",
    "    for i in range(20):\n",
    "        yes_yes_ind, no_yes_ind, added_people = getNoYes(add_count, beacon_size)\n",
    "        model_ind = np.setdiff1d(pheno1People, added_people)\n",
    "\n",
    "        # Genome Reconstruction    \n",
    "        correlations                              = builtSNPNetwork(no_yes_ind, model_ind, reference)\n",
    "        reconstructed_spectral                    = spectralClustering(no_yes_ind, add_count, correlations, reference)\n",
    "        (precision,recall,accuracy), _, matches   = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,add_count,add_count,no_yes_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Vary Added People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of No-Yes SNP's :  1032\n",
      "Recall_Micro_Avg    = 0.86 \n",
      "Precision_Micro_Avg = 0.87\n",
      "(2, 1032)\n",
      "(2, 1032)\n",
      "Recall_Micro_Avg    = 0.52 \n",
      "Precision_Micro_Avg = 0.5\n",
      "Recall_Micro_Avg    = 0.87 \n",
      "Precision_Micro_Avg = 0.88\n"
     ]
    }
   ],
   "source": [
    "counts = [2,3,5,10,20]\n",
    "beacon_size = 50\n",
    "run_count = 20\n",
    "\n",
    "results = np.zeros((3, len(counts), run_count, 3))\n",
    "\n",
    "for i in range(len(counts)):\n",
    "    for j in range(run_count):\n",
    "        yes_yes_ind, no_yes_ind, added_people = getNoYes(counts[i], beacon_size)\n",
    "        model_ind = np.setdiff1d(pheno1People, added_people)\n",
    "\n",
    "        # Genome Reconstruction    \n",
    "        correlations                = builtSNPNetwork(no_yes_ind, model_ind, reference)\n",
    "        reconstructed_spectral      = spectralClustering(no_yes_ind, counts[i], correlations, reference)\n",
    "        results[0, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,counts[i],counts[i],no_yes_ind) \n",
    "\n",
    "\n",
    "        # Baseline\n",
    "        reconstructed_baseline      = baseline_method(no_yes_ind, counts[i])\n",
    "        results[1, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T, reconstructed_baseline,counts[i],counts[i],no_yes_ind)  \n",
    "\n",
    "        # Fuzzy\n",
    "        reconstructed_fuzzy         = fuzzyClustering(no_yes_ind, counts[i], correlations, reference)\n",
    "        results[2, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T, reconstructed_fuzzy, counts[i], counts[i], no_yes_ind)  \n",
    "        \n",
    "with open(\"1F-Triple-VaryAdded.pickle\", 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Vary Beacon Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [25,50,75,100]\n",
    "add_count = 5\n",
    "run_count = 20\n",
    "\n",
    "results = np.zeros((3, len(counts), run_count, 3))\n",
    "\n",
    "for i in range(len(counts)):\n",
    "    for j in range(run_count):\n",
    "        yes_yes_ind, no_yes_ind, added_people = getNoYes(add_count, counts[i])\n",
    "        model_ind = np.setdiff1d(pheno1People, added_people)\n",
    "\n",
    "        # Genome Reconstruction    \n",
    "        correlations                = builtSNPNetwork(no_yes_ind, model_ind, reference)\n",
    "        reconstructed_spectral      = spectralClustering(no_yes_ind, add_count, correlations, reference)\n",
    "        results[0, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,add_count,add_count,no_yes_ind) \n",
    "\n",
    "\n",
    "        # Baseline\n",
    "        reconstructed_baseline      = baseline_method(no_yes_ind, add_count)\n",
    "        results[1, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T, reconstructed_baseline,add_count,add_count,no_yes_ind)  \n",
    "\n",
    "        # Fuzzy\n",
    "        reconstructed_fuzzy         = fuzzyClustering(no_yes_ind,add_count,correlations,reference)\n",
    "        results[2, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T, reconstructed_fuzzy,add_count,add_count,no_yes_ind)  \n",
    "        \n",
    "with open(\"1F-Triple-VaryBeacon.pickle\", 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Cluster Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [1,2,3,4,5,10]\n",
    "add_count = 5\n",
    "run_count = 20\n",
    "beacon_size = 50\n",
    "\n",
    "results = np.zeros((3, len(counts), run_count, 3))\n",
    "\n",
    "for i in range(len(counts)):\n",
    "    for j in range(run_count):\n",
    "        yes_yes_ind, no_yes_ind, added_people = getNoYes(add_count, beacon_size)\n",
    "        model_ind = np.setdiff1d(pheno1People, added_people)\n",
    "\n",
    "        # Genome Reconstruction    \n",
    "        correlations                = builtSNPNetwork(no_yes_ind, model_ind, reference)\n",
    "        reconstructed_spectral      = spectralClustering(no_yes_ind, add_count, correlations, reference)\n",
    "        results[0, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,add_count,counts[i],no_yes_ind) \n",
    "\n",
    "\n",
    "        # Baseline\n",
    "        reconstructed_baseline      = baseline_method(no_yes_ind, add_count)\n",
    "        results[1, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T, reconstructed_baseline,add_count,counts[i],no_yes_ind)  \n",
    "\n",
    "        # Fuzzy\n",
    "        reconstructed_fuzzy         = fuzzyClustering(no_yes_ind,add_count,correlations,reference)\n",
    "        results[2, i, j, :],_,_     = performance_f(beacon.iloc[:, added_people].values.T, reconstructed_fuzzy,add_count,counts[i],no_yes_ind)  \n",
    "        \n",
    "with open(\"1F-Triple-VaryCluster.pickle\", 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
