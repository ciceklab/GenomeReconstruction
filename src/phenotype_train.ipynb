{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import timeit\n",
    "import itertools\n",
    "import warnings\n",
    "import pickle\n",
    "import feather\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join, isfile\n",
    "from collections import Counter\n",
    "from xgboost import XGBClassifier\n",
    "from fcmeans import FCM\n",
    "import scipy.stats as stats\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, classification_report, mutual_info_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier,BalancedBaggingClassifier, EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True, formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainPath = \"../../data\"\n",
    "beacons = join(mainPath, \"beacon\")\n",
    "testSets = join(\"\", \"test_sets\")\n",
    "models = join(mainPath, \"models\")\n",
    "ceuPath = join(beacons, \"CEU\")\n",
    "opensnpPath = join(beacons, \"OpenSNP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: Load Beacon, MAF, Reference and other cached variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'EyeColor','HairType','HairColor','TanAbility','Asthma','LactoseIntolerance',#'BloodType',\n",
    "             'EarWax','Freckling','TongueRoller','RingFinger','Intolerance','WidowPeak','ADHD','Acrophobia',\n",
    "             'FingerHair','Myopia','IrritableBowel','IndexLongerBig','Photoptarmis','Migraine','RhProtein']\n",
    "with open(join(opensnpPath, \"OpenSNP_Phenotype.pickle\"), 'rb') as handle:\n",
    "    pheno = pickle.load(handle)\n",
    "pheno = pheno[features]\n",
    "pheno[pheno==\"Auburn\"] = \"Blonde\"\n",
    "pheno[pheno==\"Black\"] = \"Brown\"\n",
    "\n",
    "with open(join(opensnpPath, \"MAF.pickle\"), 'rb') as handle:\n",
    "    maf = pickle.load(handle)\n",
    "\n",
    "with open(join(opensnpPath, \"Reference.pickle\"), 'rb') as handle:\n",
    "    reference = pickle.load(handle)\n",
    "reference = reference.values\n",
    "\n",
    "with open(join(opensnpPath, \"Beacon.pickle\"), 'rb') as handle:\n",
    "    beacon = pickle.load(handle)\n",
    "\n",
    "with open(join(opensnpPath, \"BinaryBeacon.pickle\"), 'rb') as handle:\n",
    "    binary = pickle.load(handle)\n",
    "    \n",
    "with open(join(opensnpPath, \"TernaryBeacon.pickle\"), 'rb') as handle:\n",
    "    ternary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constrainted Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno5People = pheno.iloc[np.where(np.sum(pheno != \"-\", axis = 1) >=10)[0]].index\n",
    "pheno5People = pheno5People.map(str)\n",
    "pheno5People = np.where(beacon.columns.isin(pheno5People))[0]\n",
    "\n",
    "pheno1People = pheno.iloc[np.where(np.sum(pheno != \"-\", axis = 1) >= 1)[0]].index\n",
    "pheno1People = pheno1People.map(str)\n",
    "pheno1People = np.where(beacon.columns.isin(pheno1People))[0]\n",
    "\n",
    "phenoAllPeople = np.arange(beacon.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1.2: Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beacon operations\n",
    "def queryBeacon(beacon_people):\n",
    "    return binary[:, beacon_people].any(axis=1)\n",
    "\n",
    "def getMutationAt(index):\n",
    "    temp = maf.iloc[index]\n",
    "    if temp[\"minor_freq\"] == temp[\"maf\"]:\n",
    "        return temp[\"minor\"] + temp[\"minor\"] \n",
    "    else:\n",
    "        return temp[\"major\"] + temp[\"major\"] \n",
    "\n",
    "def div(n, d):\n",
    "    return n / d if d else 0\n",
    "\n",
    "def rpaCalculate(tp,fp,tn,fn):\n",
    "    recall = div(tp,(tp+fn)) \n",
    "    precision = div(tp,(tp+fp))\n",
    "    accuracy = div((tp+tn),(tp+fp+tn+fn))\n",
    "    return recall, precision, accuracy\n",
    "\n",
    "def getTrainingData(phenotype, pos, test_people):\n",
    "    # Find indices of people who has the specified feature\n",
    "    feature_label = pheno[pheno[phenotype] != \"-\"][phenotype]\n",
    "    existing = beacon.columns.isin(feature_label.index.values)\n",
    "    existing[test_people] = False \n",
    "    \n",
    "    # Get training data\n",
    "    X = binary[pos][:, existing].T\n",
    "    Y = feature_label[beacon.columns[existing]].values\n",
    "    return X, Y\n",
    "\n",
    "# Performance method\n",
    "def performance(person, reconstruction, eval_pos, reference):\n",
    "    ind = np.logical_and(person[eval_pos] != np.squeeze(reference)[eval_pos], person[eval_pos] != \"NN\")\n",
    "    tp = np.sum(reconstruction[eval_pos][ind] != np.squeeze(reference)[eval_pos][ind])\n",
    "    fn = np.sum(ind) - tp\n",
    "    fp = np.sum(reconstruction[eval_pos][~ind] != np.squeeze(reference)[eval_pos][~ind])\n",
    "    tn = np.sum(~ind) - fp\n",
    "\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def performance_f(test_people, reconstructed, add_count, cluster_count, eval_pos):\n",
    "    total_values = np.zeros((4))\n",
    "    best_matches = []\n",
    "    # For all people in victim set\n",
    "    for i in range(add_count):\n",
    "        all_combinations = np.zeros((4, cluster_count))\n",
    "        rpa = np.zeros((3, cluster_count))\n",
    "        # For each cluster obtained\n",
    "        for j in range(cluster_count):\n",
    "            all_combinations[:, j] = performance(test_people[i], reconstructed[j], eval_pos, reference)\n",
    "            rpa[:, j] = rpaCalculate(*all_combinations[:, j])\n",
    "        ind = np.argmax(rpa[0,:]*rpa[1,:])       #Best-match index\n",
    "        best_matches.append(ind)\n",
    "        total_values += all_combinations[:, ind] #Add total tp-fp-tn-fn\n",
    "    recall, precision, accuracy = rpaCalculate(*total_values)\n",
    "    print(\"Recall_Micro_Avg    =\", round(recall, 2),\"\\nPrecision_Micro_Avg =\", round(precision, 2))\n",
    "    return (precision,recall,accuracy), total_values, best_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2: Choose random people and send query to Beacon to obtain No-Yes answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoYes(add_count, beacon_size):\n",
    "\n",
    "    # Take people for added group\n",
    "    added_people = pheno5People.copy()\n",
    "    random.shuffle(added_people)\n",
    "    added_people = added_people[:add_count]\n",
    "    \n",
    "    # Take people for beacon\n",
    "    beacon_people = np.setdiff1d(phenoAllPeople, added_people)\n",
    "    random.shuffle(beacon_people)\n",
    "    beacon_people = beacon_people[:beacon_size]\n",
    "\n",
    "    # Query Beacon initially\n",
    "    before = queryBeacon(beacon_people)\n",
    "    # Add people\n",
    "    updated_beacon = np.concatenate([added_people,beacon_people])\n",
    "    # Query Beacon again\n",
    "    after = queryBeacon(updated_beacon)\n",
    "    # Find No-Yes SNPs' indices\n",
    "    no_yes_indices = np.where(np.logical_and(before==False, after==True))[0]\n",
    "    yes_yes_indices = np.where(np.logical_and(before==True, after==True))[0]\n",
    "    print(\"Number of No-Yes SNP's : \", len(no_yes_indices))\n",
    "    \n",
    "    return yes_yes_indices, no_yes_indices, added_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3: Correlation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtSNPNetwork(no_yes_indices, model_ind, reference):\n",
    "    model = ternary[no_yes_ind][:, model_ind].astype(float)\n",
    "    model[model==-1] = np.nan\n",
    "    x = pairwise_distances(model, metric = \"sokalmichener\", n_jobs=-1)\n",
    "    x = 1-np.nan_to_num(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectralClustering(no_yes_indices, add_count, x, reference, cluster_count=None):\n",
    "    if not cluster_count:\n",
    "        cluster_count = add_count\n",
    "    sc = SpectralClustering(cluster_count, affinity='precomputed', n_init=100, n_jobs=-1)\n",
    "    sc.fit(np.array(x))\n",
    "    bins = []\n",
    "    for i in range(cluster_count):\n",
    "        temp = []\n",
    "        for element in np.where(sc.labels_==i)[0]:\n",
    "            temp.append(no_yes_indices[element])\n",
    "        #print(\"Bin \" + str(i) + \" has \" + str(len(temp)) + \" SNP's\")\n",
    "        bins.append(temp)\n",
    "    reconstructed = np.array([reference.T[0] for i in range(cluster_count)])\n",
    "    for i in range(cluster_count):\n",
    "        for j in bins[i]:\n",
    "            reconstructed[i][j] = getMutationAt(j)\n",
    "    return reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genome Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Brute Force Test-Set Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiments = [(2, 20, 0.9), (3, 30, 0.8), (5, 50, 0.8), (10, 100, 0.8), (20, 100, 0.65), (30, 100, 0.6), (40, 100, 0.55)]\n",
    "\n",
    "for e in experiments:\n",
    "    add_count = e[0]\n",
    "    cluster_count = add_count\n",
    "    beacon_size = e[1]\n",
    "    target = e[2]\n",
    "    test_sets = []\n",
    "    for i in range(10):\n",
    "        precision, recall = 0, 0\n",
    "        while precision + recall < target * 2:\n",
    "            yes_yes_ind, no_yes_ind, added_people     = getNoYes(add_count, beacon_size)\n",
    "            correlations                              = builtSNPNetwork(no_yes_ind, pheno5People, reference)\n",
    "            reconstructed_spectral                    = spectralClustering(no_yes_ind, add_count, correlations, reference)\n",
    "            (precision,recall,accuracy), _, matches   = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,add_count,cluster_count,no_yes_ind)\n",
    "        gs = [yes_yes_ind, no_yes_ind, added_people]\n",
    "        test_sets.append(gs)\n",
    "    filename = str(e[0]) + \"_testset2.pkl\" \n",
    "    with open(join(beacons, filename), 'wb') as f:\n",
    "        pickle.dump(test_sets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotype Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(models, x_test, y_test, add_count, cluster_count):\n",
    "    # Predict\n",
    "    results = []\n",
    "    for i in models:\n",
    "        results.append(i[1].predict_proba(x_test))\n",
    "    labels = [i[0] for i in models]\n",
    "\n",
    "    top3, top1 = 0, 0\n",
    "    # For each person\n",
    "    for i in range(add_count):\n",
    "        test_person = y_test[labels].iloc[i]\n",
    "        available_phenotypes = np.where(test_person != \"-\")[0]\n",
    "\n",
    "        # For each reconstructed genome\n",
    "        probs = np.zeros((cluster_count))\n",
    "        for j in range(cluster_count):\n",
    "            # For each available phenotype\n",
    "            for k in available_phenotypes:\n",
    "                target_label_ind = np.where(models[k][1].classes_ == test_person[k])[0]\n",
    "                probs[j] += results[k][j][target_label_ind]# * models[k][2]\n",
    "\n",
    "        # Top k\n",
    "        matched_ind = np.argsort(probs)[-3:]\n",
    "        print(probs, \"\\n\", matched_ind, \"--\", matches[i], \"\\n\")\n",
    "        if matches[i] in matched_ind:\n",
    "            top3 += 1\n",
    "        if matches[i] == matched_ind[-1]:\n",
    "            top1 += 1\n",
    "    print(\"Top-1 Accuracy= \", top1 / add_count, \"\\tTop-3 Accuracy= \", top3 / add_count)\n",
    "    return top1 / add_count, top3 / add_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train_snps, test_people):\n",
    "    models = []\n",
    "    count = 1\n",
    "    for feature in features:\n",
    "        X, Y = getTrainingData(phenotype=feature, pos=train_snps, test_people=test_people)\n",
    "        print(\"\\n\",count, \".\", feature, \"\\tlabels=\", np.unique(Y))\n",
    "        \n",
    "        # Upsampling\n",
    "        X, Y = SMOTE().fit_sample(X, Y)\n",
    "        # Train the model\n",
    "        rf = RandomForestClassifier(class_weight='balanced_subsample',oob_score=True,n_jobs=-1)\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1)\n",
    "        model = GridSearchCV(cv=cv, estimator=rf, scoring='f1_macro', param_grid=parameters,verbose=0,n_jobs=-1)\n",
    "        result = model.fit(X, Y)\n",
    "\n",
    "        print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "        best_model = result.best_estimator_\n",
    "        best_score = (result.best_score_ + best_model.oob_score_) / 2\n",
    "        #best_model.fit(X, Y)\n",
    "        \n",
    "        if best_score > 1.2 / len(np.unique(Y)):\n",
    "            count += 1\n",
    "            print(\"Train:\", round(best_model.score(X, Y), 2), \" | Validation:\", round(best_score,2))\n",
    "            models.append((feature, model, best_score))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimators = [100]                 # n_estimators\n",
    "Depths = [3]          # max_depth (None olabilir)\n",
    "MinSample = [0.05, 0.075]           # min_samples_leaf\n",
    "MaxFeatures = [0.75]  # min_samples_leaf\n",
    "Criterion = [\"gini\"]              # criterion\n",
    "parameters = {\"max_depth\": Depths, \"min_samples_leaf\": MinSample, \"criterion\": Criterion, \"n_estimators\": Estimators, \"max_features\": MaxFeatures}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall_Micro_Avg    = 0.93 \n",
      "Precision_Micro_Avg = 0.87\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.523848 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.602299 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.69  | Validation: 0.62\n",
      "\n",
      " 2 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.630348 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.69  | Validation: 0.63\n",
      "\n",
      " 3 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.569997 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 3 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.593814 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.6\n",
      "\n",
      " 4 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.641129 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.65\n",
      "\n",
      " 5 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.665579 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.67\n",
      "\n",
      " 6 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.632225 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.62\n",
      "\n",
      " 7 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.720374 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.75  | Validation: 0.72\n",
      "\n",
      " 8 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.646986 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.64\n",
      "\n",
      " 9 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.672959 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.82  | Validation: 0.7\n",
      "\n",
      " 10 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.642736 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.76  | Validation: 0.64\n",
      "\n",
      " 11 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.582331 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.602562 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.61\n",
      "\n",
      " 12 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.599276 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.78  | Validation: 0.61\n",
      "\n",
      " 13 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.512397 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 13 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.493295 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 13 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.557567 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 13 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.498778 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 13 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.521679 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 13 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.699246 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.7\n",
      "[6.20 5.78 4.69] \n",
      " [2 1 0] -- 2 \n",
      "\n",
      "[7.52 7.12 6.49] \n",
      " [2 1 0] -- 0 \n",
      "\n",
      "[3.98 3.80 4.28] \n",
      " [1 0 2] -- 2 \n",
      "\n",
      "Top-1 Accuracy=  0.6666666666666666 \tTop-3 Accuracy=  1.0\n",
      "Recall_Micro_Avg    = 0.92 \n",
      "Precision_Micro_Avg = 0.81\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.532938 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.568505 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.624564 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.68  | Validation: 0.63\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.566718 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.637837 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.64\n",
      "\n",
      " 3 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.670402 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.67\n",
      "\n",
      " 4 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.684877 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.75  | Validation: 0.69\n",
      "\n",
      " 5 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.574104 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 5 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.686963 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.74  | Validation: 0.7\n",
      "\n",
      " 6 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.577171 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 6 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.669801 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.8  | Validation: 0.67\n",
      "\n",
      " 7 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.647682 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.64\n",
      "\n",
      " 8 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.473754 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 8 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.587911 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.625873 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.74  | Validation: 0.62\n",
      "\n",
      " 9 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.582262 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 9 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.539358 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 9 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.480920 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 9 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.497614 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 9 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.453636 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 9 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.702196 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.71\n",
      "[4.81 5.15 5.66] \n",
      " [0 1 2] -- 2 \n",
      "\n",
      "[3.61 4.10 4.58] \n",
      " [0 1 2] -- 0 \n",
      "\n",
      "[3.36 5.05 5.00] \n",
      " [0 2 1] -- 2 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall_Micro_Avg    = 0.86 \n",
      "Precision_Micro_Avg = 0.88\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.567467 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.568830 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.647799 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.63\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.575284 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.644387 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.64\n",
      "\n",
      " 3 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.692512 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.7\n",
      "\n",
      " 4 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.704239 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.7\n",
      "\n",
      " 5 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.569035 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 5 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.683185 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.69\n",
      "\n",
      " 6 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.598281 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.61\n",
      "\n",
      " 7 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.705394 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.76  | Validation: 0.71\n",
      "\n",
      " 8 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.617175 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.75  | Validation: 0.62\n",
      "\n",
      " 9 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.555125 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 9 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.631849 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.64\n",
      "\n",
      " 10 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.583155 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 10 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.574675 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 10 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.499708 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 10 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.445642 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 10 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.593575 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 10 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.461774 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 10 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.700757 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.75  | Validation: 0.72\n",
      "[3.57 4.08 6.31] \n",
      " [0 1 2] -- 1 \n",
      "\n",
      "[2.10 2.64 2.12] \n",
      " [0 2 1] -- 0 \n",
      "\n",
      "[3.94 3.82 5.45] \n",
      " [1 0 2] -- 2 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n",
      "Recall_Micro_Avg    = 0.97 \n",
      "Precision_Micro_Avg = 0.97\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.526269 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.567768 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.631036 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.66  | Validation: 0.64\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.598488 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.581508 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.595538 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.67  | Validation: 0.61\n",
      "\n",
      " 3 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.665627 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.74  | Validation: 0.68\n",
      "\n",
      " 4 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.552922 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 4 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.663001 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.67\n",
      "\n",
      " 5 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.600705 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 5 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.652810 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.77  | Validation: 0.64\n",
      "\n",
      " 6 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.530910 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 6 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.450328 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 6 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.636738 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.76  | Validation: 0.61\n",
      "\n",
      " 7 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.532354 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 7 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.571767 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 7 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.479344 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 7 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.501440 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 7 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.462700 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 7 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.524473 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 7 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.645895 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.66\n",
      "[1.33 1.54 1.54] \n",
      " [0 2 1] -- 2 \n",
      "\n",
      "[2.46 2.13 1.15] \n",
      " [2 1 0] -- 0 \n",
      "\n",
      "[1.24 1.13 1.60] \n",
      " [1 0 2] -- 1 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n",
      "Recall_Micro_Avg    = 0.84 \n",
      "Precision_Micro_Avg = 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.506518 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.566962 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.623782 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.65  | Validation: 0.62\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.568619 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.631979 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.69  | Validation: 0.64\n",
      "\n",
      " 3 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.690839 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.69\n",
      "\n",
      " 4 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.703129 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.71\n",
      "\n",
      " 5 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.572977 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 5 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.659094 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.68  | Validation: 0.67\n",
      "\n",
      " 6 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.595296 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.65  | Validation: 0.6\n",
      "\n",
      " 7 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.724118 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.77  | Validation: 0.72\n",
      "\n",
      " 8 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.642134 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.64\n",
      "\n",
      " 9 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.515051 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 9 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.624620 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.68  | Validation: 0.63\n",
      "\n",
      " 10 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.603501 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.6\n",
      "\n",
      " 11 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.605323 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.521878 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 11 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.535265 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.551553 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.449036 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.714005 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.71\n",
      "[3.04 2.75 3.55] \n",
      " [1 0 2] -- 2 \n",
      "\n",
      "[3.36 3.33 4.66] \n",
      " [1 0 2] -- 0 \n",
      "\n",
      "[3.44 3.50 4.48] \n",
      " [0 1 2] -- 1 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n",
      "Recall_Micro_Avg    = 0.84 \n",
      "Precision_Micro_Avg = 0.86\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.552528 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.503461 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.649835 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.67  | Validation: 0.64\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.565856 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.612819 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.68  | Validation: 0.63\n",
      "\n",
      " 3 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.682483 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.68\n",
      "\n",
      " 4 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.686336 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.7\n",
      "\n",
      " 5 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.590992 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 5 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.685710 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.69  | Validation: 0.68\n",
      "\n",
      " 6 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.602858 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.63  | Validation: 0.61\n",
      "\n",
      " 7 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.700686 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.7\n",
      "\n",
      " 8 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.592833 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.6\n",
      "\n",
      " 9 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.444195 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 9 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.618564 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.66  | Validation: 0.63\n",
      "\n",
      " 10 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.612620 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.65  | Validation: 0.62\n",
      "\n",
      " 11 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.548315 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 11 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.466679 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.480112 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.571007 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 11 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.537364 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 11 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.725064 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.74  | Validation: 0.72\n",
      "[3.70 3.44 4.53] \n",
      " [1 0 2] -- 0 \n",
      "\n",
      "[5.34 5.35 5.95] \n",
      " [0 1 2] -- 2 \n",
      "\n",
      "[3.21 2.99 3.73] \n",
      " [1 0 2] -- 1 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall_Micro_Avg    = 0.98 \n",
      "Precision_Micro_Avg = 0.97\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.538223 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.562271 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.633966 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.68  | Validation: 0.64\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.595479 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.591624 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.62  | Validation: 0.6\n",
      "\n",
      " 3 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.656327 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.69  | Validation: 0.65\n",
      "\n",
      " 4 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.626553 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.64\n",
      "\n",
      " 5 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.545608 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 5 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.668632 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.67\n",
      "\n",
      " 6 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.574425 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 6 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.633300 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.75  | Validation: 0.65\n",
      "\n",
      " 7 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.621858 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.74  | Validation: 0.62\n",
      "\n",
      " 8 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.529499 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.529539 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.544605 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.565519 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.432280 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 8 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.472759 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.509275 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.513778 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.668712 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.75  | Validation: 0.69\n",
      "[2.34 2.46 1.17] \n",
      " [2 0 1] -- 2 \n",
      "\n",
      "[2.05 2.54 1.18] \n",
      " [2 0 1] -- 2 \n",
      "\n",
      "[3.52 2.71 2.93] \n",
      " [1 2 0] -- 0 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n",
      "Recall_Micro_Avg    = 0.97 \n",
      "Precision_Micro_Avg = 0.97\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.531533 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.544830 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.651415 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.66\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.593421 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.662256 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.67  | Validation: 0.66\n",
      "\n",
      " 3 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.680656 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.69  | Validation: 0.68\n",
      "\n",
      " 4 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.694872 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.69\n",
      "\n",
      " 5 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.585076 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 5 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.691053 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.69\n",
      "\n",
      " 6 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.607870 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.65  | Validation: 0.61\n",
      "\n",
      " 7 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.719871 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.72\n",
      "\n",
      " 8 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.580737 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.475114 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.662129 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.66\n",
      "\n",
      " 9 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.621104 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.67  | Validation: 0.63\n",
      "\n",
      " 10 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.545425 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 10 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.565872 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 10 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.543490 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 10 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.522098 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 10 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.524298 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 10 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.714586 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.72\n",
      "[2.81 2.05 2.60] \n",
      " [1 2 0] -- 1 \n",
      "\n",
      "[5.17 4.34 7.06] \n",
      " [1 0 2] -- 0 \n",
      "\n",
      "[4.43 4.16 7.14] \n",
      " [1 0 2] -- 2 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n",
      "Recall_Micro_Avg    = 0.88 \n",
      "Precision_Micro_Avg = 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.518947 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.602648 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.67  | Validation: 0.61\n",
      "\n",
      " 2 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.634329 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.67  | Validation: 0.64\n",
      "\n",
      " 3 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.603007 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 3 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.641975 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.64\n",
      "\n",
      " 4 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.678866 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.68\n",
      "\n",
      " 5 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.672020 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.77  | Validation: 0.69\n",
      "\n",
      " 6 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.602250 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.67  | Validation: 0.62\n",
      "\n",
      " 7 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.695102 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.75  | Validation: 0.71\n",
      "\n",
      " 8 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.600220 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.71  | Validation: 0.6\n",
      "\n",
      " 9 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.644183 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.76  | Validation: 0.66\n",
      "\n",
      " 10 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.579749 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.79  | Validation: 0.62\n",
      "\n",
      " 11 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.555466 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 11 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.633359 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.64\n",
      "\n",
      " 12 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.544263 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 12 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.581668 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 12 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.550993 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 12 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.561468 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 12 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.552650 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 12 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.451729 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 12 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.704021 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.74  | Validation: 0.71\n",
      "[4.52 5.28 5.13] \n",
      " [0 2 1] -- 0 \n",
      "\n",
      "[4.71 8.12 9.07] \n",
      " [0 1 2] -- 2 \n",
      "\n",
      "[3.73 5.36 5.10] \n",
      " [0 2 1] -- 1 \n",
      "\n",
      "Top-1 Accuracy=  0.6666666666666666 \tTop-3 Accuracy=  1.0\n",
      "Recall_Micro_Avg    = 0.91 \n",
      "Precision_Micro_Avg = 0.82\n",
      "\n",
      " 1 . EyeColor \tlabels= ['Blue' 'Brown']\n",
      "Best: 0.545117 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairType \tlabels= ['Curly' 'Straight']\n",
      "Best: 0.537054 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 1 . HairColor \tlabels= ['Blonde' 'Brown']\n",
      "Best: 0.635971 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.63\n",
      "\n",
      " 2 . TanAbility \tlabels= ['No' 'Yes']\n",
      "Best: 0.579087 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . Asthma \tlabels= ['No' 'Yes']\n",
      "Best: 0.509554 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 2 . LactoseIntolerance \tlabels= ['Intolerant' 'Tolerant']\n",
      "Best: 0.630158 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.7  | Validation: 0.64\n",
      "\n",
      " 3 . EarWax \tlabels= ['Dry' 'Wet']\n",
      "Best: 0.636555 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.73  | Validation: 0.65\n",
      "\n",
      " 4 . Freckling \tlabels= ['No' 'Yes']\n",
      "Best: 0.582291 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 4 . TongueRoller \tlabels= ['No' 'Yes']\n",
      "Best: 0.621871 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.64  | Validation: 0.63\n",
      "\n",
      " 5 . RingFinger \tlabels= ['No' 'Yes']\n",
      "Best: 0.539530 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 5 . Intolerance \tlabels= ['Intolerant' 'NoIntolerance']\n",
      "Best: 0.642090 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.77  | Validation: 0.67\n",
      "\n",
      " 6 . WidowPeak \tlabels= ['No' 'Yes']\n",
      "Best: 0.549972 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 6 . ADHD \tlabels= ['No' 'Yes']\n",
      "Best: 0.565085 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 6 . Acrophobia \tlabels= ['No' 'Yes']\n",
      "Best: 0.598811 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.76  | Validation: 0.62\n",
      "\n",
      " 7 . FingerHair \tlabels= ['No' 'Yes']\n",
      "Best: 0.621430 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "Train: 0.62  | Validation: 0.62\n",
      "\n",
      " 8 . Myopia \tlabels= ['High' 'Low']\n",
      "Best: 0.482431 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . IrritableBowel \tlabels= ['No' 'Yes']\n",
      "Best: 0.475868 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . IndexLongerBig \tlabels= ['BigLonger' 'IndexLonger']\n",
      "Best: 0.579668 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . Photoptarmis \tlabels= ['No' 'Yes']\n",
      "Best: 0.456389 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "\n",
      " 8 . Migraine \tlabels= ['No' 'Yes']\n",
      "Best: 0.564356 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.075, 'n_estimators': 100}\n",
      "\n",
      " 8 . RhProtein \tlabels= ['Negative' 'Positive']\n",
      "Best: 0.659814 using {'criterion': 'gini', 'max_depth': 3, 'max_features': 0.75, 'min_samples_leaf': 0.05, 'n_estimators': 100}\n",
      "Train: 0.72  | Validation: 0.66\n",
      "[2.82 4.65 4.29] \n",
      " [0 2 1] -- 2 \n",
      "\n",
      "[3.94 3.54 4.16] \n",
      " [1 0 2] -- 2 \n",
      "\n",
      "[1.97 1.92 2.28] \n",
      " [1 0 2] -- 0 \n",
      "\n",
      "Top-1 Accuracy=  0.3333333333333333 \tTop-3 Accuracy=  1.0\n",
      "Top-1=  0.4 \tTop-3=  1.0\n"
     ]
    }
   ],
   "source": [
    "experiments = [(2,20, 0.9),(3,30, 0.8),(5,50, 0.8),(10,100, 0.8),(20,100, 0.65)]\n",
    "\n",
    "e = experiments[1]\n",
    "add_count = e[0]\n",
    "\n",
    "with open(join(testSets, str(add_count) + \"_testset2.pkl\"), 'rb') as f:\n",
    "    test_sets = pickle.load(f)\n",
    "\n",
    "top1s, top3s = [], []\n",
    "for i in range(10):\n",
    "    yes_yes_ind, no_yes_ind, added_people = test_sets[i]\n",
    "    model_ind = np.setdiff1d(pheno1People, added_people)\n",
    "     \n",
    "    # Genome Reconstruction    \n",
    "    correlations                              = builtSNPNetwork(no_yes_ind, model_ind, reference)\n",
    "    reconstructed_spectral                    = spectralClustering(no_yes_ind, add_count, correlations, reference)\n",
    "    (precision,recall,accuracy), _, matches   = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,add_count,add_count,no_yes_ind)\n",
    "    \n",
    "    # Phenotype Prediction\n",
    "    models = train_models(train_snps=no_yes_ind, test_people=added_people)\n",
    "    \n",
    "    # Test Data\n",
    "    x_test = (reconstructed_spectral[:, no_yes_ind] != reference[no_yes_ind].T).astype(np.int8)\n",
    "    y_test = pheno.loc[beacon.columns[added_people]]\n",
    "    \n",
    "    # Performance\n",
    "    top1, top3 = evaluate_ensemble(models, x_test, y_test, add_count, add_count)\n",
    "    top1s.append(top1)\n",
    "    top3s.append(top3)\n",
    "print(\"Top-1= \", np.mean(top1s), \"\\tTop-3= \", np.mean(top3s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(2,20, 0.9),(3,30, 0.8),(5,50, 0.8),(10,100, 0.8)]#,(20,100, 0.65)]\n",
    "res = []\n",
    "for e in experiments:\n",
    "    add_count = e[0]\n",
    "    beacon_size = e[1]\n",
    "    with open(join(testSets, str(add_count) + \"_testset2.pkl\"), 'rb') as f:\n",
    "        test_sets = pickle.load(f)\n",
    "    top1s = []\n",
    "    top3s = []\n",
    "    for i in range(10):\n",
    "        yes_yes_ind, no_yes_ind, added_people = test_sets[i]\n",
    "        model_ind = np.setdiff1d(pheno1People, added_people)\n",
    "\n",
    "        # Genome Reconstruction    \n",
    "        correlations                              = builtSNPNetwork(no_yes_ind, model_ind, reference)\n",
    "        reconstructed_spectral                    = spectralClustering(no_yes_ind, add_count, correlations, reference)\n",
    "        (precision,recall,accuracy), _, matches   = performance_f(beacon.iloc[:, added_people].values.T,reconstructed_spectral,add_count,add_count,no_yes_ind)\n",
    "\n",
    "        # Phenotype Prediction\n",
    "        models = train_models(train_snps=no_yes_ind, test_people=added_people)\n",
    "\n",
    "        # Test Data\n",
    "        x_test = (reconstructed_spectral[:, no_yes_ind] != reference[no_yes_ind].T).astype(np.int8)\n",
    "        y_test = pheno.loc[beacon.columns[added_people]]\n",
    "\n",
    "        # Performance\n",
    "        top1, top3 = evaluate_ensemble(models, x_test, y_test, add_count, add_count)\n",
    "        top1s.append(top1)\n",
    "        top3s.append(top3)\n",
    "    print(\"Top-1= \", np.mean(top1s), \"\\tTop-3= \", np.mean(top3s))\n",
    "    res.append((top1s,top3s))\n",
    "    with open(join(beacons, str(add_count) + \".pkl\"), 'wb') as f:\n",
    "        pickle.dump((top1s,top3s), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train_models(train_snps, test_people):\n",
    "    models = []\n",
    "    count = 1\n",
    "    for feature in features:\n",
    "        X, Y = getTrainingData(phenotype=feature, pos=train_snps, test_people=test_people)\n",
    "        print(\"\\n\",count, \".\", feature, \"\\tlabels=\", np.unique(Y), \"\\t\",end=\"\", flush=True)\n",
    "\n",
    "        X, Y = SMOTE().fit_sample(X, Y)\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=4,criterion='entropy',class_weight='balanced_subsample',max_features=X.shape[1]//4,\n",
    "                                       min_samples_leaf=4,bootstrap=True,verbose=0,n_jobs=-1,oob_score=True)\n",
    "    \n",
    "        #model = GridSearchCV(cv=10, estimator=rf, scoring='f1_macro', param_grid=parameters,verbose=2,n_jobs=-1)\n",
    "        result = model.fit(X, Y)\n",
    "\n",
    "        #print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "        #best_estimator = result.best_estimator_\n",
    "        #best_estimator.fit(X, Y)\n",
    "        print(model.oob_score_)\n",
    "        if model.oob_score_ > 1.2 / len(np.unique(Y)):\n",
    "            count += 1\n",
    "            print(\"\\nTrain:\", round(model.score(X, Y), 2), \" | Out-of-Bag:\", round(model.oob_score_,2))\n",
    "            models.append((feature, model, model.oob_score_))\n",
    "    return models\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train_models(train_snps, test_people):\n",
    "    models = []\n",
    "    count = 1\n",
    "    for feature in features:\n",
    "        X, Y = getTrainingData(phenotype=feature, pos=train_snps, test_people=test_people)\n",
    "        print(\"\\n\",count, \".\", feature, \"\\tlabels=\", np.unique(Y), \"\\t\",end=\"\", flush=True)\n",
    "\n",
    "        X, Y = SMOTE().fit_sample(X, Y)\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=16,criterion='entropy',class_weight='balanced_subsample',max_features=X.shape[1]//2,\n",
    "                                       min_samples_leaf=2,bootstrap=True,verbose=0,n_jobs=-1,oob_score=True)\n",
    "    \n",
    "        '''model = BalancedRandomForestClassifier(n_estimators=100, max_depth=16, min_samples_split=2, min_samples_leaf=2, min_weight_fraction_leaf=0,\n",
    "                                            max_features=None, max_leaf_nodes=None, bootstrap=True, oob_score=True, replacement=False,\n",
    "                                            n_jobs=-1, warm_start=False, criterion='entropy', class_weight=\"balanced_subsample\")'''\n",
    "        \n",
    "        model.fit(X, Y)\n",
    "        if model.oob_score_ > 1.2 / len(np.unique(Y)):\n",
    "            count += 1\n",
    "            print(\"\\nTrain:\", round(model.score(X, Y), 2), \" | Out-of-Bag:\", round(model.oob_score_,2))\n",
    "            models.append((feature, model, model.oob_score_))\n",
    "    return models\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train_models(train_snps, test_people):\n",
    "    models = []\n",
    "    count = 1\n",
    "    for feature in features:\n",
    "        X, Y = getTrainingData(phenotype=feature, pos=train_snps, test_people=test_people)\n",
    "\n",
    "        print(\"\\n\",count, \".\", feature, \"\\tlabels=\", np.unique(Y), \"\\t\",end=\"\", flush=True)\n",
    "        \n",
    "        for epoch in range(25):\n",
    "            # Train/Val Split\n",
    "            x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y)\n",
    "            \n",
    "            # Upsampling\n",
    "            x_train, y_train = SMOTE().fit_sample(x_train, y_train)\n",
    "            \n",
    "            # Train the model\n",
    "            model = RandomForestClassifier(n_estimators=100,max_depth=4,min_samples_leaf=8,criterion=\"entropy\",class_weight='balanced_subsample',bootstrap=True,verbose=0,n_jobs=-1)\n",
    "\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_val)\n",
    "\n",
    "            # Performance\n",
    "            result = classification_report(y_val, y_pred, output_dict=True)\n",
    "            isBetter = result[\"macro avg\"][\"f1-score\"] > 1.2 / len(np.unique(y_train))\n",
    "            if isBetter:\n",
    "                count += 1\n",
    "                print(\"\\nTrain:\", round(model.score(x_train, y_train), 2), \" | Test:\", round(model.score(x_val, y_val),2))\n",
    "                print(classification_report(y_val, y_pred, output_dict=False))\n",
    "                #model.fit(np.concatenate([x_train, x_val], axis=0), np.concatenate([y_train, y_val], axis=0))\n",
    "                models.append((feature, model, result[\"macro avg\"][\"f1-score\"]))\n",
    "                break\n",
    "            print(\"|\", end=\"\", flush=True)\n",
    "    return models\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Reconstruction average performans iyi değil\n",
    "2. Bilmemiz gereken fenotip sayısı > 10-15\n",
    "3. Performans nasıl report edeceğiz ?\n",
    "4. Top-1 olmazsa nasıl Membership kısmına bağlayacağız\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Stash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# SINGLE MODELS\n",
    "model = XGBClassifier(objective=\"multi:softprob\",eval_metric=\"auc\",num_class=len(np.unique(y_train)),n_jobs=-1,learning_rate=0.001,tree_method=\"hist\",\n",
    "                          gamma=3,reg_lambda=10,max_depth=10,max_delta_step=1,colsample_bytree=0.95,scale_pos_weight=10000,num_parallel_tree=8,booster=\"dart\")\n",
    "\n",
    "model = BalancedRandomForestClassifier(n_estimators=150, max_depth=None, min_samples_split=5, min_samples_leaf=2, min_weight_fraction_leaf=0,\n",
    "                                            max_features='auto', max_leaf_nodes=None, bootstrap=True, oob_score=False, replacement=False,\n",
    "                                            n_jobs=-1, warm_start=True, class_weight=\"balanced\")\n",
    "        \n",
    "model = LogisticRegression(penalty='l1',random_state=0,solver='saga',multi_class='multinomial',n_jobs=-1,C=10,max_iter=100)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=128, max_depth=8,class_weight='balanced_subsample',verbose=0,n_jobs=-1)\n",
    "\n",
    "model = BalancedBaggingClassifier()\n",
    "\n",
    "# PIPELINE\n",
    "selecter = SelectKBest(chi2, k=20000)\n",
    "xgb = XGBClassifier(objective=\"multi:softprob\",eval_metric=\"error\",num_class=len(np.unique(y_train)),n_jobs=-1,\n",
    "                      learning_rate=0.05, gamma=1, max_depth=20,subsample=1, colsample_bytree=1, scale_pos_weight=10000, num_parallel_tree=32)\n",
    "estimators = [('selection', selecter), ('brc', xgb)]\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# SAMPLING METHODS\n",
    "smote = SMOTE()\n",
    "x_train, y_train = smote.fit_sample(x_train, y_train)\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "x_train, y_train = rus.fit_resample(x_train, y_train)\n",
    "\n",
    "tom = TomekLinks(ratio=\"majority\")\n",
    "x_train, y_train = tom.fit_sample(x_train, y_train)\n",
    "\n",
    "cc = ClusterCentroids()\n",
    "x_train, y_train = cc.fit_sample(x_train, y_train)\n",
    "\n",
    "\n",
    "# GRID SEARCH                                            \n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1)\n",
    "model = RandomizedSearchCV(cv=5, estimator=xgboost, param_distributions=parameters,n_iter=100,verbose=10,n_jobs=-1)\n",
    "\n",
    "\n",
    "# SAVE MODELS\n",
    "with open(join(models, 'Model_' + feature + '.pkl'), 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "\n",
    "Gammas    = np.linspace(0, 10, num=11)           # gamma\n",
    "Depths    = np.linspace(4, 10, num=7, dtype=int) # max_depth\n",
    "Deltas    = np.logspace(0, 4, num=5, base=2)     # max_delta_step\n",
    "Learning  = np.logspace(-3, 0, num=4)            # learning_rate\n",
    "Lambdas   = np.logspace(-3, 0, num=4)            # lambda\n",
    "MinChild  = np.logspace(0, 5, num=6, base=2)     # min_child_weight\n",
    "Scale     = np.logspace(0, 6, num=7)             # scale_pos_weight\n",
    "Subsample = [1, 0.75]                            # subsample\n",
    "ColSample = [1, 0.75]                            # colsample_bytree\n",
    "Forest    = [100]                                # num_parallel_tree\n",
    "\n",
    "parameters = {\"learning_rate\":Learning, \"gamma\":Gammas, \"max_depth\":Depths, \n",
    "              \"max_delta_step\":Deltas, \"lambda\":Lambdas, \"min_child_weight\":MinChild, \n",
    "              \"subsample\":Subsample, \"colsample_bytree\":ColSample, \"scale_pos_weight\":Scale,\n",
    "              \"num_parallel_tree\":Forest}\n",
    "              \n",
    "Estimators= np.logspace(2, 4, num=3, dtype=int)  # n_estimators\n",
    "Depths    = np.linspace(4, 10, num=7, dtype=int) # max_depth (None olabilir)\n",
    "MinSplit  = np.linspace(2, 8, num=7, dtype=int)  # min_samples_split\n",
    "MinSample = np.linspace(1, 5, num=6, dtype=int)  # min_samples_leaf\n",
    "Impurity  = np.logspace(0, 6, num=7, dtype=int)  # min_impurity_decrease\n",
    "Criterion = [\"gini\", \"entropy\"]                  # criterion\n",
    "\n",
    "parameters = {\"max_depth\":Depths, \"min_samples_split\":MinSplit, \"min_samples_leaf\":MinSample, \n",
    "              \"min_impurity_decrease\":Impurity, \"criterion\":Criterion, \"n_estimators\":Estimators}\n",
    "              \n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "              \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(join(opensnpPath, \"QuadBeacon.pickle\"), 'rb') as handle:\n",
    "    quad = pickle.load(handle)\n",
    "# 0: one minor 1: double minor 2: double major 3: NN\n",
    "\n",
    "gs = [yes_yes_ind, no_yes_ind, added_people]\n",
    "with open(join(beacons, \"goodsetup.pkl\"), 'wb') as f:\n",
    "    pickle.dump(gs, f)\n",
    "\n",
    "with open(join(beacons, \"goodsetup.pkl\"), 'rb') as f:\n",
    "    yes_yes_ind, no_yes_ind, added_people = pickle.load(f)\n",
    "yes_yes_ind, no_yes_ind, added_people\n",
    "\n",
    "#original_x = binary[no_yes_ind][:,added_people]\n",
    "#test_x = original_x.T\n",
    "#matches2 = np.arange(10)\n",
    "\n",
    "#from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, TomekLinks\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, LeakyReLU, Dropout\n",
    "#from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def train_models2(train_snps, test_people, parameters):\n",
    "    models = []\n",
    "    for feature in features:\n",
    "        X, Y = getTrainingData(phenotype=feature, pos=train_snps, test_people=test_people)\n",
    "\n",
    "        print(\"\\n\", feature, \"\\tlabels=\", np.unique(Y), \"\\t\",end=\"\", flush=True)\n",
    "\n",
    "        for epoch in range(1):\n",
    "            # Upsampling\n",
    "            smote = SMOTE()\n",
    "            X, Y = smote.fit_sample(X, Y)\n",
    "            \n",
    "            # Train the model\n",
    "            rf = RandomForestClassifier(n_estimators=100, max_depth=16,class_weight='balanced_subsample',verbose=0,n_jobs=-1)\n",
    "            model = RandomizedSearchCV(cv=10, estimator=rf, param_distributions=parameters,n_iter=100,verbose=10,n_jobs=-1)\n",
    "            result = model.fit(X, Y)\n",
    "            \n",
    "            print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "\n",
    "            best_model = model.best_estimator_\n",
    "            models.append((feature, best_model, np.mean(result.cv_results_['mean_test_score']), result.cv_results_))\n",
    "        break\n",
    "    return models\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot_confusion_matrix(cm=np.array([[tp_total,fp_total],\n",
    "                                   [fn_total,tn_total]]),\n",
    "                  target_names=['mutation', 'normal'],\n",
    "                  title=\"Confusion Matrix\")\n",
    "   \n",
    "# Use rare indices or not ? \n",
    "threshold = 0.01\n",
    "condition = np.logical_and(maf['maf'] < threshold, maf['maf'] > 0)\n",
    "rare_percent = maf[condition].shape[0] / len(giant) * 100\n",
    "rare_indices = np.where(condition==True)[0]\n",
    "rare_names = maf[condition].index.values\n",
    "print(len(rare_indices))\n",
    "\n",
    "\n",
    "r = small.columns[np.random.choice(len(small.columns), size=45, replace=False)]\n",
    "    \n",
    "%%time\n",
    "# Set NN to MAF values\n",
    "for i in range(mutation_beacon.shape[0]):\n",
    "    mutation_beacon[i][ny_beacon[ind].values[i] == \"NN\"] = maf.iloc[no_yes_ind][\"maf\"][i]\n",
    "mutation_beacon\n",
    "\n",
    "beacon = pd.read_csv(join(opensnpPath, \"Beacon.csv\"),sep=',',dtype=\"category\",header=None)\n",
    "\n",
    "le = LabelEncoder()\n",
    "beacon.apply(le.fit_transform)\n",
    "\n",
    "# Confusion matrix plotter method\n",
    "def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def onehot_initialization_v3(a):\n",
    "    ncols = a.max() + 1\n",
    "    labels_one_hot = (a.ravel()[np.newaxis] == np.arange(ncols)[:, np.newaxis]).T\n",
    "    labels_one_hot.shape = a.shape + (ncols,)\n",
    "    return labels_one_hot\n",
    "\n",
    "x = onehot_initialization_v3(quad.values.T)\n",
    "x = x.astype(np.int8)\n",
    "# Smoothen\n",
    "    for t in range(len(results)):\n",
    "        idx = np.argmax(results[t], axis=-1)\n",
    "        results[t] = np.zeros(results[t].shape )\n",
    "        results[t][np.arange(results[t].shape[0]), idx] = 1\n",
    "        \n",
    "ny_snps = binary[no_yes_ind][:,added_people].T\n",
    "matches = np.arange(add_count)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## 3. Mutual Information\n",
    "def get_pvalues(X, tempy):\n",
    "    t11 = np.sum(X.T * tempy, axis=1)\n",
    "    t10 = np.sum(X.T * (1-tempy), axis=1)\n",
    "    t01 = np.sum((1-X.T) * tempy, axis=1)\n",
    "    t00 = np.sum((1-X.T) * (1-tempy), axis=1)\n",
    "    t = np.array([np.array([t00[i], t01[i], t10[i], t11[i]]).reshape(2,2) for i in range(X.shape[1])])\n",
    "    values = np.array([stats.fisher_exact(i)[0] for i in t])\n",
    "    probs = np.nan_to_num(values / (1+values), nan=1)\n",
    "    probs[probs == 0] = 1e-8\n",
    "    return probs\n",
    "\n",
    "def train_mi(train_snps, test_people):\n",
    "    m_infos = []\n",
    "    for feature in features:\n",
    "        X, Y = getTrainingData(phenotype=feature, pos=train_snps, test_people=test_people)\n",
    "\n",
    "        print(feature, end=\"\", flush=True)\n",
    "        labels = np.unique(Y)\n",
    "        mis = np.zeros((len(labels), X.shape[1]))\n",
    "        for i in range(len(labels)):\n",
    "            tempy = Y.copy()\n",
    "            tempy[Y != labels[i]] = 0\n",
    "            tempy[Y == labels[i]] = 1\n",
    "            mis[i] = get_pvalues(X, tempy)\n",
    "            #tempy[tempy != labels[i]] = \"Other\"\n",
    "            #mis[i] = mutual_info_classif(X, tempy, discrete_features='auto', n_neighbors=3, copy=True)\n",
    "        m_infos.append((feature,mis))\n",
    "    return m_infos\n",
    "\n",
    "def test_mi(mis, x_test, y_test):\n",
    "    correct = 0\n",
    "    # For each person\n",
    "    for i in range(len(y_test)):\n",
    "        test_person = y_test.iloc[i]\n",
    "        scores = np.ones((len(y_test)), dtype=float)\n",
    "        # For each reconstructed genome\n",
    "        for j in range(len(y_test)):\n",
    "            available_phenotypes = np.where(test_person != \"-\")[0]\n",
    "            for k in available_phenotypes:\n",
    "                label = test_person[k]\n",
    "                available_labels = np.setdiff1d(pheno.iloc[:, k], \"-\")\n",
    "                pos = np.where(available_labels == label)[0]\n",
    "                scores[j] += np.mean(mis[k][1][:, x_test[j]][pos])\n",
    "                #scores[j] += np.log(np.mean(1+1e-8-mis[k][1][:, 1-x_test[j]][pos]))\n",
    "\n",
    "        print(scores)\n",
    "        matched_ind = np.argsort(scores)[-3:]\n",
    "        print(matched_ind, \"--\", matches[i])\n",
    "        print()\n",
    "        if matches[i] in matched_ind:\n",
    "            correct += 1\n",
    "    return correct / len(y_test)\n",
    " \n",
    "# Phenotype Prediction\n",
    "x_test = (reconstructed_spectral != reference.T[0])[:, no_yes_ind]\n",
    "y_test = pheno.loc[beacon.columns[added_people]]\n",
    "print(\"Set: \", i+1)\n",
    "mis = train_mi(train_snps=no_yes_ind, test_people=added_people)\n",
    "accuracy = test_mi(mis, x_test, y_test)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "overall_accuracy.append(accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Deep Learning\n",
    "models = []\n",
    "count = 0\n",
    "random.shuffle(features)\n",
    "for feature in features:\n",
    "    if feature == \"Sex\":\n",
    "        continue\n",
    "    # Find indices of people who has the specified feature\n",
    "    feature_label = pheno[pheno[feature] != \"-\"][feature]\n",
    "    existing = beacon.columns.isin(feature_label.index.values)\n",
    "    existing[added_people] = False \n",
    "    \n",
    "    X = binary[no_yes_ind][:, existing].T\n",
    "    Y = feature_label[beacon.columns[existing]].values\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    y = enc.fit_transform(Y.reshape(-1, 1)).toarray()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y)\n",
    "    \n",
    "    # Train / Test\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_dim=X.shape[1], activation=LeakyReLU(alpha=0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(np.unique(Y)), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=len(x_train))\n",
    "    y_pred = model.predict_classes(x_test, verbose=0)\n",
    "\n",
    "    # Performance\n",
    "    result = classification_report(np.where(y_test)[1], y_pred, output_dict=True)\n",
    "    isBetter = result[\"macro avg\"][\"f1-score\"] > 1.0 / len(np.unique(y_train))\n",
    "    if isBetter:\n",
    "        count += 1\n",
    "        print(count, \".\", feature, \" --> \", np.unique(Y))\n",
    "        #print(\"Train:\", round(model.score(x_train, y_train), 2), \" | Test:\", round(model.score(x_test, y_test),2))\n",
    "        print(round(result[\"macro avg\"][\"f1-score\"], 2), \">\" , 1.0 / len(np.unique(y_train)), \"\\n\")\n",
    "        models.append((feature, model, result[\"macro avg\"][\"f1-score\"]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 2. Including Yes-Yes SNP's\n",
    "isRandom = False\n",
    "percentage = 2\n",
    "if isRandom:\n",
    "    yy_count = len(yes_yes_ind) * percentage // 100\n",
    "    yy_pos = np.random.choice(yes_yes_ind, yy_count, replace=False)  \n",
    "    train_ind = np.sort(np.concatenate([yy_pos, no_yes_ind]))\n",
    "else:\n",
    "    yy_count = len(yes_yes_ind) * percentage // 100\n",
    "    yy_pos = yes_yes_ind[np.argsort(np.var(ternary[yes_yes_ind], axis=1))[::-1]][:yy_count]\n",
    "    train_ind = np.sort(np.concatenate([yy_pos, no_yes_ind]))\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "# Get no-yes reconstructed snps\n",
    "ny_pos  = np.where(np.in1d(train_ind, no_yes_ind))[0]\n",
    "ny_snps = reconstructed_spectral[:, no_yes_ind]\n",
    "ny_snps = np.logical_and(ny_snps == reference[no_yes_ind].T, ny_snps != \"NN\")\n",
    "ny_snps = ny_snps.astype(np.int8)\n",
    "\n",
    "correct = 0\n",
    "labels = [i[0] for i in models]\n",
    "test_y = pheno.loc[beacon.columns[added_people]]\n",
    "\n",
    "# For each person\n",
    "for i in range(len(test_y)):\n",
    "    test_person = test_y[labels].iloc[i]\n",
    "    # Predict each cluster\n",
    "    results = []\n",
    "    test_x = binary[train_ind][:, added_people[i]]\n",
    "    test_x = np.expand_dims(test_x, axis=0)\n",
    "    test_x = np.repeat(test_x,add_count,axis=0)\n",
    "    test_x[:, ny_pos] = ny_snps\n",
    "    # For each model\n",
    "    for m in models:\n",
    "        results.append(m[1].predict_proba(test_x))\n",
    "    \n",
    "    # For each reconstructed genome\n",
    "    probs = np.zeros((len(test_y)))\n",
    "    for j in range(len(test_y)):\n",
    "        available_phenotypes = np.where(test_person != \"-\")[0]\n",
    "        # For each available phenotype\n",
    "        for k in available_phenotypes:\n",
    "            target_label_ind = np.where(models[k][1].classes_ == test_person[k])[0]\n",
    "            probs[j] += results[k][j][target_label_ind]\n",
    "    \n",
    "    print(probs)\n",
    "    # Top k\n",
    "    matched_ind = np.argsort(probs)[-3:]\n",
    "    print(matched_ind, \"--\", matches[i])\n",
    "    print()\n",
    "    if matches[i] in matched_ind:\n",
    "        correct += 1\n",
    "    \n",
    "acc = correct / len(test_y)\n",
    "acc\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
